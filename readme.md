# HW1. Loan Approval Prediction 

### Как ведёт себя модель по мере обучения? Сколько эпох оптимально?

`Train Loss=0.2270, Train ROC-AUC=0.9046, Eval Loss=0.2186, Eval ROC-AUC=0.9162`

Loss падает, ROC-AUC растёт (темпы замедляются). 
Даже при длительном обучении нет переобучения. 
Модель слишком простая, не может достичь оптимального уровня

## Эксперимент 2. Модель побольше

### Стало ли лучше? Как теперь ведёт себя модель?

`Train Loss=0.2193, Train ROC-AUC=0.9089, Eval Loss=0.2122, Eval ROC-AUC=0.9214`

Увеличение размера модели дало заметный прирост метрик

## Эксперимент 3. Skip Connections, Batch Norms

### Стало ли лучше? Как теперь ведёт себя модель?

`Train Loss=0.2199, Train ROC-AUC=0.9108, Eval Loss=0.2346, Eval ROC-AUC=0.9119`

Добавление skip-соединений и BN ухудшило метрики. 
Возможно, нужен другой lr для новой архитектуры

## Эксперимент 4. Dropout

### Как меняется качество модели в зависимости от p? Как ведёт себя модель с разными p?

`Train Loss=0.2393, Train ROC-AUC=0.8972, Eval Loss=0.2352, Eval ROC-AUC=0.9137`

Лучший результат при dropout=0.01. Большие значения избыточны из-за простой структуры. 
При высоком dropout теряется важная информация между слоями

## Эксперимент 5. Weight Decay, Learning Rate

### Как зависит качество итоговой модели от этих двух параметров? Как ведёт себя модель с разными lambda и lr?

`Train Loss=0.2067, Train ROC-AUC=0.9176, Eval Loss=0.2076, Eval ROC-AUC=0.9229`

Оптимум при lr=0.1 и wd=0.001, но это может быть локальный минимум.
При lr=0.001 результаты стабильнее. wd=0.001 всегда лучше из-за отсутствия переобучения


